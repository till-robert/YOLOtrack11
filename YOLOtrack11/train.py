# Ultralytics YOLO üöÄ, AGPL-3.0 license

from copy import copy

from ultralytics.models import yolo
from .model import ZAxisModel
from ultralytics.utils import DEFAULT_CFG, RANK, colorstr, emojis,clean_url
from ultralytics.data.utils import check_cls_dataset, check_det_dataset
import math
import torch.nn as nn
import random
from ultralytics.utils.torch_utils import de_parallel
from .dataset import YOLOtrackDataset
from .val import ZAxisValidator
class ZAxisTrainer(yolo.detect.DetectionTrainer):


    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """Initialize a ZAxisTrainer object with given arguments."""
        if overrides is None:
            overrides = {}
        overrides["task"] = "zaxis"
        # overrides["augment"] = False
        super().__init__(cfg, overrides, _callbacks)

    def get_model(self, cfg=None, weights=None, verbose=True):
        """Return ZAxisModel initialized with specified config and weights."""
        model = ZAxisModel(cfg, ch=1, nc=self.data["nc"], verbose=verbose and RANK == -1)
        if weights:
            model.load(weights)

        return model

    def get_validator(self):
        """Return an instance of ZAxisValidator for validation of YOLO model."""
        self.loss_names = "box_loss", "cls_loss", "dfl_loss", "zaxis_loss"
        return ZAxisValidator(self.test_loader, save_dir=self.save_dir, args=copy(self.args))
    def get_dataset(self):
        """
        Get train, val path from data dict if it exists.
        Returns None if data format is not recognized.
        """
        try:
            if self.args.task == "classify":
                data = check_cls_dataset(self.args.data)
            elif self.args.data.split(".")[-1] in {"yaml", "yml"} or self.args.task in {
                "detect",
                "segment",
                "pose",
                "obb",
                "zaxis",
            }:
                data = check_det_dataset(self.args.data)
                if "yaml_file" in data:
                    self.args.data = data["yaml_file"]  # for validating 'yolo train data=url.zip' usage
        except Exception as e:
            raise RuntimeError(emojis(f"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}")) from e
        self.data = data
        return data["train"], data.get("val") or data.get("test")
    
    def build_dataset(self, img_path, mode="train", batch=None):
        """
        Build YOLO Dataset.

        Args:
            img_path (str): Path to the folder containing images.
            mode (str): `train` mode or `val` mode, users are able to customize different augmentations for each mode.
            batch (int, optional): Size of batches, this is for `rect`. Defaults to None.
        """
        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)
        cfg  = self.args
        rect = False
        
        return YOLOtrackDataset(
            img_path=img_path,
            imgsz=cfg.imgsz,
            batch_size=batch,
            augment=cfg.augment,#mode == "train",  # augmentation
            hyp=cfg,  # TODO: probably add a get_hyps_from_cfg function
            rect=cfg.rect or rect,  # rectangular batches
            cache=cfg.cache or None,
            single_cls=cfg.single_cls or False,
            stride=int(gs),
            pad=0.0 if mode == "train" else 0.5,
            prefix=colorstr(f"{mode}: "),
            task=cfg.task,
            classes=cfg.classes,
            data=self.data,
            fraction=cfg.fraction if mode == "train" else 1.0,
        )
    
    def preprocess_batch(self, batch):
        """Preprocesses a batch of images by scaling and converting to float."""
        if(batch["img"].type() == "torch.UInt16Tensor"):
                batch["img"] = batch["img"].to(self.device, non_blocking=True).float() / 65535
        else:
            batch["img"] = batch["img"].to(self.device, non_blocking=True).float() / 255
        if self.args.multi_scale:
            imgs = batch["img"]
            sz = (
                random.randrange(int(self.args.imgsz * 0.5), int(self.args.imgsz * 1.5 + self.stride))
                // self.stride
                * self.stride
            )  # size
            sf = sz / max(imgs.shape[2:])  # scale factor
            if sf != 1:
                ns = [
                    math.ceil(x * sf / self.stride) * self.stride for x in imgs.shape[2:]
                ]  # new shape (stretched to gs-multiple)
                imgs = nn.functional.interpolate(imgs, size=ns, mode="bilinear", align_corners=False)
            batch["img"] = imgs
        return batch